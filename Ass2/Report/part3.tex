\chapter{Discussion on Architecture}

\section{Modularity of architecture}
\begin{description}
\item[a:] The architecture is strongly modular in the sense that different aspects of it are completely modularised and separated into different http services.
\item[b:] If the book store client service crashes, the stock manager and server service is unaffected and keeps running smoothly, and vice versa.
\item[c:] If all services are run locally in the same JVM, they will not have the same isolation. If the JVM crashes, everything crashes.
\end{description}

\section{Naming}
\begin{description}
\item[a:] There are multiple naming services in the architecture. There is port naming, books have ISBN naming, and RPC uses enums to identify the desired functions to be executed. Furthermore these RPC calls specify the privilege levels of the client using a naming scheme that pre-fixes the path in the PRC. Additionally we utilise DNS when running this service remote.
\item[b:] DNS are used to resolve the IP address from the hostnames/domain names and port pairs when a book store or stock manager attempts to connect remotely.
\end{description}

\section{RPC semantics used}
The architecture implements exactly-once RPC semantics, since each request is fulfilled exactly once. For instance, when buying a book, if it is in stock you will get one, but if it is not, it will be ordered once.

\section{Proxy Servers}
\begin{description}
\item[a:] It is safe to use proxy servers with the architecture of Figure 2, since there is only one back-end server, and thus no possibility of race conditions arising.
\item[b:] We would put them in front of the BookStoreHTTPServer. They would have little to no effect, however, again since there are not multiple back-end servers to scale against.
\end{description}

\section{Bottlenecks}
As mentioned above, the single back-end server is a bottleneck with respect to the number of clients. This problem is mainly due to the fact that we need shared memory or data storage somewhere to ensure consistency, which reduces the scalability of this solution greatly.

\section{Effects of server crash}
\begin{description}
\item[a:] In the current implementation of this system we cannot use the web proxy for load balancing, and thus the difference that any client would experience would lie in the web proxies ability to cache relevant static resources.
\item[b:] Yes. If the web proxies were used to cache simple get requests or static replys, the clients would be able to continue to request these in spite of the backend server being down. However, they would not be able to modify anything or look up non-cached resources.
\item[c:] Web caching would make things more difficult, as we would need to keep track of when the cached data becomes invalidated and must be deleted or recached.
\end{description}